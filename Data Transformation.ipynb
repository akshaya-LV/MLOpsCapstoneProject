{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "62ffb31b-40bf-4590-af7a-a92c8dfa9038",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from databricks.feature_engineering import FeatureEngineeringClient\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d1236d81-9707-48c9-9feb-ca6ee59c3f09",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2abdc9b-4e3e-425e-bf25-b8a8e9520725",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#-------- Data Ingestion---------------------------\n",
    "# Read data\n",
    "df = spark.read.table(\"customer_shopping_data_2\")\n",
    "\n",
    "# Show the first few rows of the DataFrame\n",
    "df.show()\n",
    "\n",
    "# Print the schema (column names and data types)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13996498-cbf1-47f9-9337-51a8d2c04353",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "retail_df = df.toPandas()\n",
    "retail_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8886e2fc-4ed2-4cf4-8e58-eeef84513b4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#-------- Segment Customers ---------------------------\n",
    "# Calculate total revenue for each customer\n",
    "customer_revenue = retail_df.groupby('customer_id').agg({'price': 'sum'}).rename(columns={'price': 'total_revenue'})\n",
    "#print(customer_segment.head())\n",
    "\n",
    "customer_revenue.rename(columns={'price': 'total_revenue'}, inplace=True)\n",
    "\n",
    "# Calculate percentile thresholds\n",
    "p33 = customer_revenue['total_revenue'].quantile(0.33)\n",
    "p66 = customer_revenue['total_revenue'].quantile(0.66)\n",
    "\n",
    "# Define a function to segment customers\n",
    "def segment_customer(total_revenue):\n",
    "    if total_revenue <= p33:\n",
    "        return 'Low-Value'\n",
    "    elif total_revenue <= p66:\n",
    "        return 'Medium-Value'\n",
    "    else:\n",
    "        return 'High-Value'\n",
    "\n",
    "# Apply the function to create the new column\n",
    "customer_revenue['customer_segment'] = customer_revenue['total_revenue'].apply(segment_customer)\n",
    "\n",
    "# Merge df1 with df2 on the 'customer_id' column\n",
    "# 'how='left'' ensures all customers from df1 are kept\n",
    "merged_df = pd.merge(retail_df, customer_revenue, on='customer_id', how='left')\n",
    "\n",
    "print(\"Merged DataFrame:\")\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09480e34-51ab-4dcb-b47f-101b4cded7c6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#ordinal field for segment column\n",
    "# Define the mapping dictionary\n",
    "segment_mapping = {\n",
    "    'Low-Value': 1,\n",
    "    'Medium-Value': 2,\n",
    "    'High-Value': 3\n",
    "}\n",
    "\n",
    "# Apply the mapping to create a new column with ordinal values\n",
    "merged_df['cust_segment_ordinal'] = merged_df['customer_segment'].map(segment_mapping)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f9b5a732-6275-486a-8f4a-f23066521f06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install databricks-feature-engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21850d27-b4e2-4d93-8571-7afda6f1be54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark_df = spark.createDataFrame(merged_df)\n",
    "\n",
    "# 2. Engineer features from the raw data\n",
    "\n",
    "# 3. Initialize the Feature Engineering client\n",
    "fe = FeatureEngineeringClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c8868c6-89ca-4c02-a92d-edd4be95b8a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE CATALOG IF NOT EXISTS retail_catalog;\n",
    "CREATE SCHEMA IF NOT EXISTS retail_catalog.retail_schema;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "80cb7ea9-2c8d-48fe-b05f-638db3d5bc08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 4. Define the table name and primary keys\n",
    "# Replace 'your_catalog', 'your_schema', and 'your_table' with your desired names.\n",
    "feature_table_name = \"retail_catalog.retail_schema.features\"\n",
    "primary_keys = [\"invoice_no\"]\n",
    "\n",
    "# 5. Create the feature table and write the data\n",
    "\n",
    "# The `create_table` method takes the DataFrame to infer the schema.\n",
    "# `write_table` populates the table with data.\n",
    "fe.create_table(\n",
    "    name=feature_table_name,\n",
    "    df=spark_df,\n",
    "    primary_keys = primary_keys\n",
    "    #mode=\"merge\" # or 'merge' for incremental updates\n",
    ")\n",
    "\n",
    "print(f\"Feature table '{feature_table_name}' created and populated successfully.\")\n",
    "\n",
    "# You can now see this table in the Databricks UI under the 'Catalog Explorer'."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "3"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 5574285582068150,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Data Transformation",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
